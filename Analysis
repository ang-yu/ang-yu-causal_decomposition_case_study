
library("caret")
library("nnet")
library("gbm")
library("ranger")
library("gdata")
library("xtable")

library("cdgd")

rm(list=ls(all=TRUE))

data <- readRDS("/Users/Ang/Desktop/Research/Causal_decomposition/Data/data_cleaned.rds")

data$gender <- as.numeric(data$gender)-1

data$parental_presence <- as.numeric(data$parental_presence)-1

data$n_sib <- as.numeric(data$n_sib)-1

data$urban <- as.numeric(data$urban)-1

data$edu_exp <- as.numeric(data$edu_exp)-2
data$edu_exp[data$edu_exp==-1] <- 0

data$age <- as.numeric(data$age)-1

data$friend_edu_exp <- as.numeric(data$friend_edu_exp)-2
data$friend_edu_exp[data$friend_edu_exp==-1] <- 0

data$foreign_lang <- as.numeric(data$foreign_lang)-1

data$SMSA1 <- NA
data$SMSA1[data$SMSA==0 & !is.na(data$SMSA)] <- 1
data$SMSA1[data$SMSA!=0 & !is.na(data$SMSA)] <- 0
data$SMSA2 <- NA
data$SMSA2[data$SMSA==1 & !is.na(data$SMSA)] <- 1
data$SMSA2[data$SMSA!=1 & !is.na(data$SMSA)] <- 0
data$SMSA3 <- NA
data$SMSA3[data$SMSA==2 & !is.na(data$SMSA)] <- 1
data$SMSA3[data$SMSA!=2 & !is.na(data$SMSA)] <- 0
data$SMSA4 <- NA
data$SMSA4[data$SMSA==3 & !is.na(data$SMSA)] <- 1
data$SMSA4[data$SMSA!=3 & !is.na(data$SMSA)] <- 0

data$mother_seperate <- as.numeric(data$mother_seperate)-1

data$school_satis1 <- NA
data$school_satis1[(data$school_satisfaction==1 | data$school_satisfaction==2) & !is.na(data$school_satisfaction)] <- 1
data$school_satis1[data$school_satisfaction!=1 & data$school_satisfaction!=2 & !is.na(data$school_satisfaction)] <- 0
data$school_satis2 <- NA
data$school_satis2[data$school_satisfaction==3 & !is.na(data$school_satisfaction)] <- 1
data$school_satis2[data$school_satisfaction!=3 & !is.na(data$school_satisfaction)] <- 0
data$school_satis3 <- NA
data$school_satis3[data$school_satisfaction==4 & !is.na(data$school_satisfaction)] <- 1
data$school_satis3[data$school_satisfaction!=4 & !is.na(data$school_satisfaction)] <- 0

data$region1 <- NA
data$region1[data$region==1 & !is.na(data$region)] <- 1
data$region1[data$region!=1 & !is.na(data$region)] <- 0
data$region2 <- NA
data$region2[data$region==2 & !is.na(data$region)] <- 1
data$region2[data$region!=2 & !is.na(data$region)] <- 0
data$region3 <- NA
data$region3[data$region==3 & !is.na(data$region)] <- 1
data$region3[data$region!=3 & !is.na(data$region)] <- 0
data$region4 <- NA
data$region4[data$region==4 & !is.na(data$region)] <- 1
data$region4[data$region!=4 & !is.na(data$region)] <- 0

data$m_work <- as.numeric(data$m_work)-1

data$race1 <- NA
data$race1[data$race=="Other" & !is.na(data$race)] <- 1
data$race1[data$race!="Other" & !is.na(data$race)] <- 0
data$race2 <- NA
data$race2[data$race=="Black" & !is.na(data$race)] <- 1
data$race2[data$race!="Black" & !is.na(data$race)] <- 0
data$race3 <- NA
data$race3[data$race=="Hispanic" & !is.na(data$race)] <- 1
data$race3[data$race!="Hispanic" & !is.na(data$race)] <- 0

data$completion <- as.numeric(data$completion)-1

data$pincome_1 <- NA
data$pincome_1[data$parental_income_rank>=0.60 & !is.na(data$parental_income_rank)] <- 1
data$pincome_1[data$parental_income_rank<0.60 & !is.na(data$parental_income_rank)] <- 0

data$pincome_2 <- NA
data$pincome_2[data$parental_income_rank<=0.40 & !is.na(data$parental_income_rank)] <- 1
data$pincome_2[data$parental_income_rank>0.40 & !is.na(data$parental_income_rank)] <- 0

data <- data[!is.na(data$pincome_1) & (data$pincome_1==1 | data$pincome_2==1), ]
colMeans(is.na(data))
data <- na.omit(data)   # from 3295 to 2008

covariates <- c("AFQT","gender","medu","parental_presence","n_sib","urban","edu_exp","age",
                "friend_edu_exp","rotter_score","rosenberg_irt_score","foreign_lang","m_work",
                "SMSA2","SMSA3","SMSA4","mother_seperate","school_satis2","school_satis3",
                "region2","region3","region4","race2","race3","parental_income_rank")

##### Unconditional decomposition
# The Q variable should be listed first to ensure consistency with conditional decomposition
result_pa <- cdgd0_pa(Y="adult_income_rank",D="completion",G="pincome_1",
                    X=covariates,
                    data=data)

set.seed(1)
result_gbm <- cdgd0_ml(Y="adult_income_rank",D="completion",G="pincome_1",
      X=covariates,
      data=data,algorithm="gbm")

set.seed(1)
result_nnet <- cdgd0_ml(Y="adult_income_rank",D="completion",G="pincome_1",
                    X=covariates,
                    data=data,algorithm="nnet")

#set.seed(1)
#result_ranger <- cdgd0_ml(Y="adult_income_rank",D="completion",G="pincome_1",
#                        X=covariates,
#                        data=data,algorithm="ranger")
### Since the default setting for ranger produces exact 0's and 1's in the denominator of the weight, we use a set of tailored hyperparameters for ranger

Y="adult_income_rank"
D="completion"
G="pincome_1"
X=covariates

set.seed(1)
# estimate the nuisance functions within each group, so that the final estimates are independent across groups
sample1 <- sample(nrow(data), floor(nrow(data)/2), replace=FALSE)
sample2 <- setdiff(1:nrow(data), sample1)

message <- utils::capture.output( YgivenDGX.Model.sample1 <- caret::train(stats::as.formula(paste(Y, paste(D,G,paste(X,collapse="+"),sep="+"), sep="~")), data=data[sample1,], method="ranger",
                                                                          trControl=caret::trainControl(method="cv")) )

# outcome regression model
message <- utils::capture.output( YgivenDGX.Model.sample1 <- caret::train(stats::as.formula(paste(Y, paste(D,G,paste(X,collapse="+"),sep="+"), sep="~")), data=data[sample1,], method="ranger",
                                                                          trControl=caret::trainControl(method="boot", number=15),
                                                                          tuneGrid=expand.grid(mtry=c(10,15,20),splitrule=c("variance"),min.node.size=c(200,250,300))) )
message <- utils::capture.output( YgivenDGX.Model.sample2 <- caret::train(stats::as.formula(paste(Y, paste(D,G,paste(X,collapse="+"),sep="+"), sep="~")), data=data[sample2,], method="ranger",
                                                                          trControl=caret::trainControl(method="boot", number=15),
                                                                          tuneGrid=expand.grid(mtry=c(10,15,20),splitrule=c("variance"),min.node.size=c(200,250,300))) )

# propensity score model
data[,D] <- as.factor(data[,D])
levels(data[,D]) <- c("D0","D1")  # necessary for caret implementation of ranger

message <- utils::capture.output( DgivenGX.Model.sample1 <- caret::train(stats::as.formula(paste(D, paste(G,paste(X,collapse="+"),sep="+"), sep="~")), data=data[sample1,], method="ranger",
                                                                         trControl=caret::trainControl(method="boot", number=15, classProbs=TRUE),
                                                                         tuneGrid=expand.grid(mtry=c(10,15,20),splitrule=c("gini"),min.node.size=c(200,250,300))) )
message <- utils::capture.output( DgivenGX.Model.sample2 <- caret::train(stats::as.formula(paste(D, paste(G,paste(X,collapse="+"),sep="+"), sep="~")), data=data[sample2,], method="ranger",
                                                                         trControl=caret::trainControl(method="boot", number=15, classProbs=TRUE),
                                                                         tuneGrid=expand.grid(mtry=c(10,15,20),splitrule=c("gini"),min.node.size=c(200,250,300))) )
data[,D] <- as.numeric(data[,D])-1

### cross-fitted predictions
YgivenGX.Pred_D0 <- YgivenGX.Pred_D1 <- DgivenGX.Pred <- rep(NA, nrow(data))

pred_data <- data
pred_data[,D] <- 0
YgivenGX.Pred_D0[sample2] <- stats::predict(YgivenDGX.Model.sample1, newdata = pred_data[sample2,])
YgivenGX.Pred_D0[sample1] <- stats::predict(YgivenDGX.Model.sample2, newdata = pred_data[sample1,])

pred_data <- data
pred_data[,D] <- 1
YgivenGX.Pred_D1[sample2] <- stats::predict(YgivenDGX.Model.sample1, newdata = pred_data[sample2,])
YgivenGX.Pred_D1[sample1] <- stats::predict(YgivenDGX.Model.sample2, newdata = pred_data[sample1,])

pred_data <- data
DgivenGX.Pred[sample2] <- stats::predict(DgivenGX.Model.sample1, newdata = pred_data[sample2,], type="prob")[,2]
DgivenGX.Pred[sample1] <- stats::predict(DgivenGX.Model.sample2, newdata = pred_data[sample1,], type="prob")[,2]

result_ranger <- cdgd0_manual(Y=Y,D=D,G=G,
                              YgivenGX.Pred_D0=YgivenGX.Pred_D0,
                              YgivenGX.Pred_D1=YgivenGX.Pred_D1,
                              DgivenGX.Pred=DgivenGX.Pred,
                              data=data)

### Bar plots
plotdf_pa <- as.data.frame(cbind(c("Total","Baseline","Prevalence","Effect","Selection"),result_pa$results))
plotdf_nnet <- as.data.frame(cbind(c("Total","Baseline","Prevalence","Effect","Selection"),result_nnet$results))
plotdf_gbm <- as.data.frame(cbind(c("Total","Baseline","Prevalence","Effect","Selection"),result_gbm$results))
plotdf_ranger <- as.data.frame(cbind(c("Total","Baseline","Prevalence","Effect","Selection"),result_ranger$results))
colnames(plotdf_pa)[1:2] <- colnames(plotdf_nnet)[1:2] <- colnames(plotdf_gbm)[1:2] <- colnames(plotdf_ranger)[1:2] <- c("Component","Estimate")

plotdf <- as.data.frame(rbind(plotdf_pa,plotdf_nnet,plotdf_gbm,plotdf_ranger))
plotdf$Model <- factor(c(rep("Param",5),rep("Nnet",5),rep("GBM",5),rep("Ranger",5)), levels=c("Nnet","GBM","Ranger","Param"))

plotdf <- plotdf[plotdf$Component!="Total",]
plotdf$Component <- factor(plotdf$Component, levels=c("Baseline","Prevalence","Effect","Selection"))

plot_uncond <- ggplot(plotdf, aes(x=Component, y=Estimate, fill=Model)) +
  geom_bar(stat="identity", position=position_dodge()) +
  geom_errorbar(aes(ymin=Estimate-qnorm(0.975)*se, ymax=Estimate+qnorm(0.975)*se), width=.2, linewidth=0.4,
                position=position_dodge(.9))+
  scale_fill_brewer(palette="Paired") + theme_minimal() +
  geom_hline(yintercept=result_pa$results$point[1], linetype="dashed") +
  geom_hline(yintercept=0) +
  annotate("text", x=3.15, y=0.19, label= "Total disparity", size=3.3) +
  coord_cartesian(ylim=c(-0.08,0.23), expand=FALSE) +
  scale_y_continuous(breaks=c(-0.05,0,0.05,0.1,0.15,0.2)) +
  theme(text=element_text(size=11))

ggsave(paste("/Users/Ang/Desktop/Research/Causal_decomposition/unconditional_",Sys.Date(),".jpg", sep=""), plot_uncond, width=5, height=3.5)



##### Conditional decomposition
cond_result_pa <- cdgd1_pa(Y="adult_income_rank",D="completion",G="pincome_1",Q="AFQT",
                         X=covariates[!covariates%in%"AFQT"],
                         data=data)

set.seed(1)
cond_result_gbm <- cdgd1_ml(Y="adult_income_rank",D="completion",G="pincome_1",Q="AFQT",
                    X=covariates[!covariates%in%"AFQT"],
                    data=data,algorithm="gbm")

set.seed(1)
cond_result_nnet <- cdgd1_ml(Y="adult_income_rank",D="completion",G="pincome_1",Q="AFQT",
                     X=covariates[!covariates%in%"AFQT"],
                     data=data,algorithm="nnet")

# Since the default setting for ranger produces exact 0's and 1's in the denominator of the weight, we use a set of tailored hyperparameters for ranger

Y="adult_income_rank"
D="completion"
G="pincome_1"
Q="AFQT"
X=covariates[!covariates%in%"AFQT"]

set.seed(1)
# estimate the nuisance functions with cross-fitting
sample1 <- sample(nrow(data), floor(nrow(data)/2), replace=FALSE)
sample2 <- setdiff(1:nrow(data), sample1)

# outcome regression model

message <- utils::capture.output( YgivenDGXQ.Model.sample1 <- caret::train(stats::as.formula(paste(Y, paste(D,G,Q,paste(X,collapse="+"),sep="+"), sep="~")), data=data[sample1,], method="ranger",
                                                                           trControl=caret::trainControl(method="boot", number=15),
                                                                           tuneGrid=expand.grid(mtry=c(10,15,20),splitrule=c("variance"),min.node.size=c(200,250,300))) )
message <- utils::capture.output( YgivenDGXQ.Model.sample2 <- caret::train(stats::as.formula(paste(Y, paste(D,G,Q,paste(X,collapse="+"),sep="+"), sep="~")), data=data[sample2,], method="ranger",
                                                                           trControl=caret::trainControl(method="boot", number=15),
                                                                           tuneGrid=expand.grid(mtry=c(10,15,20),splitrule=c("variance"),min.node.size=c(200,250,300))) )

# propensity score model
data[,D] <- as.factor(data[,D])
levels(data[,D]) <- c("D0","D1")  # necessary for caret implementation of ranger

message <- utils::capture.output( DgivenGXQ.Model.sample1 <- caret::train(stats::as.formula(paste(D, paste(G,Q,paste(X,collapse="+"),sep="+"), sep="~")), data=data[sample1,], method="ranger",
                                                                          trControl=caret::trainControl(method="boot", number=15, classProbs=TRUE),
                                                                          tuneGrid=expand.grid(mtry=c(10,15,20),splitrule=c("gini"),min.node.size=c(200,250,300))) )
message <- utils::capture.output( DgivenGXQ.Model.sample2 <- caret::train(stats::as.formula(paste(D, paste(G,Q,paste(X,collapse="+"),sep="+"), sep="~")), data=data[sample2,], method="ranger",
                                                                          trControl=caret::trainControl(method="boot", number=15, classProbs=TRUE),
                                                                          tuneGrid=expand.grid(mtry=c(10,15,20),splitrule=c("gini"),min.node.size=c(200,250,300))) )
data[,D] <- as.numeric(data[,D])-1

# cross-fitted predictions
YgivenGXQ.Pred_D0 <- YgivenGXQ.Pred_D1 <- DgivenGXQ.Pred <- rep(NA, nrow(data))

pred_data <- data
pred_data[,D] <- 0
YgivenGXQ.Pred_D0[sample2] <- stats::predict(YgivenDGXQ.Model.sample1, newdata = pred_data[sample2,])
YgivenGXQ.Pred_D0[sample1] <- stats::predict(YgivenDGXQ.Model.sample2, newdata = pred_data[sample1,])

pred_data <- data
pred_data[,D] <- 1
YgivenGXQ.Pred_D1[sample2] <- stats::predict(YgivenDGXQ.Model.sample1, newdata = pred_data[sample2,])
YgivenGXQ.Pred_D1[sample1] <- stats::predict(YgivenDGXQ.Model.sample2, newdata = pred_data[sample1,])

pred_data <- data
DgivenGXQ.Pred[sample2] <- stats::predict(DgivenGXQ.Model.sample1, newdata = pred_data[sample2,], type="prob")[,2]
DgivenGXQ.Pred[sample1] <- stats::predict(DgivenGXQ.Model.sample2, newdata = pred_data[sample1,], type="prob")[,2]

# Estimate E(Y_d | Q,g)
YgivenGXQ.Pred_D1_ncf <- YgivenGXQ.Pred_D0_ncf <- DgivenXQ.Pred_ncf <- rep(NA, nrow(data)) # ncf stands for non-cross-fitted

pred_data <- data
pred_data[,D] <- 1
YgivenGXQ.Pred_D1_ncf[sample1] <- stats::predict(YgivenDGXQ.Model.sample1, newdata = pred_data[sample1,])
YgivenGXQ.Pred_D1_ncf[sample2] <- stats::predict(YgivenDGXQ.Model.sample2, newdata = pred_data[sample2,])

pred_data <- data
pred_data[,D] <- 0
YgivenGXQ.Pred_D0_ncf[sample1] <- stats::predict(YgivenDGXQ.Model.sample1, newdata = pred_data[sample1,])
YgivenGXQ.Pred_D0_ncf[sample2] <- stats::predict(YgivenDGXQ.Model.sample2, newdata = pred_data[sample2,])

DgivenXQ.Pred_ncf[sample1] <- stats::predict(DgivenGXQ.Model.sample1, newdata = pred_data[sample1,], type="prob")[,2]
DgivenXQ.Pred_ncf[sample2] <- stats::predict(DgivenGXQ.Model.sample2, newdata = pred_data[sample2,], type="prob")[,2]

# IPOs for modelling E(Y_d | Q,g)
IPO_D0_ncf <- (1-data[,D])/(1-DgivenXQ.Pred_ncf)/mean((1-data[,D])/(1-DgivenXQ.Pred_ncf))*(data[,Y]-YgivenGXQ.Pred_D0_ncf) + YgivenGXQ.Pred_D0_ncf
IPO_D1_ncf <- data[,D]/DgivenXQ.Pred_ncf/mean(data[,D]/DgivenXQ.Pred_ncf)*(data[,Y]-YgivenGXQ.Pred_D1_ncf) + YgivenGXQ.Pred_D1_ncf

data_temp <- data[,c(G,Q)]
data_temp$IPO_D0_ncf <- IPO_D0_ncf
data_temp$IPO_D1_ncf <- IPO_D1_ncf

message <- utils::capture.output( Y0givenGQ.Model.sample1 <- caret::train(stats::as.formula(paste("IPO_D0_ncf", paste(G,Q,sep="+"), sep="~")), data=data_temp[sample1,], method="ranger",
                                                                          trControl=caret::trainControl(method="boot", number=15),
                                                                          tuneGrid=expand.grid(mtry=c(1,2),splitrule=c("variance"),min.node.size=c(150,200))) )
message <- utils::capture.output( Y0givenGQ.Model.sample2 <- caret::train(stats::as.formula(paste("IPO_D0_ncf", paste(G,Q,sep="+"), sep="~")), data=data_temp[sample2,], method="ranger",
                                                                          trControl=caret::trainControl(method="boot", number=15),
                                                                          tuneGrid=expand.grid(mtry=c(1,2),splitrule=c("variance"),min.node.size=c(150,200))) )
message <- utils::capture.output( Y1givenGQ.Model.sample1 <- caret::train(stats::as.formula(paste("IPO_D1_ncf", paste(G,Q,sep="+"), sep="~")), data=data_temp[sample1,], method="ranger",
                                                                          trControl=caret::trainControl(method="boot", number=15),
                                                                          tuneGrid=expand.grid(mtry=c(1,2),splitrule=c("variance"),min.node.size=c(150,200))) )
message <- utils::capture.output( Y1givenGQ.Model.sample2 <- caret::train(stats::as.formula(paste("IPO_D1_ncf", paste(G,Q,sep="+"), sep="~")), data=data_temp[sample2,], method="ranger",
                                                                          trControl=caret::trainControl(method="boot", number=15),
                                                                          tuneGrid=expand.grid(mtry=c(1,2),splitrule=c("variance"),min.node.size=c(150,200))) )

Y0givenQ.Pred_G0 <- Y0givenQ.Pred_G1 <- Y1givenQ.Pred_G0 <- Y1givenQ.Pred_G1 <- rep(NA, nrow(data))

pred_data <- data
pred_data[,G] <- 1
Y0givenQ.Pred_G1[sample2] <- stats::predict(Y0givenGQ.Model.sample1, newdata = pred_data[sample2,])  # cross-fitting is used
Y0givenQ.Pred_G1[sample1] <- stats::predict(Y0givenGQ.Model.sample2, newdata = pred_data[sample1,])
Y1givenQ.Pred_G1[sample2] <- stats::predict(Y1givenGQ.Model.sample1, newdata = pred_data[sample2,])
Y1givenQ.Pred_G1[sample1] <- stats::predict(Y1givenGQ.Model.sample2, newdata = pred_data[sample1,])

pred_data <- data
pred_data[,G] <- 0
Y0givenQ.Pred_G0[sample2] <- stats::predict(Y0givenGQ.Model.sample1, newdata = pred_data[sample2,])  # cross-fitting is used
Y0givenQ.Pred_G0[sample1] <- stats::predict(Y0givenGQ.Model.sample2, newdata = pred_data[sample1,])
Y1givenQ.Pred_G0[sample2] <- stats::predict(Y1givenGQ.Model.sample1, newdata = pred_data[sample2,])
Y1givenQ.Pred_G0[sample1] <- stats::predict(Y1givenGQ.Model.sample2, newdata = pred_data[sample1,])

# Estimate E(D | Q,g')
data[,D] <- as.factor(data[,D])
levels(data[,D]) <- c("D0","D1")  # necessary for caret implementation of ranger

message <- utils::capture.output( DgivenGQ.Model.sample1 <- caret::train(stats::as.formula(paste(D, paste(G,Q,sep="+"), sep="~")), data=data[sample1,], method="ranger",
                                                                         trControl=caret::trainControl(method="boot", number=15, classProbs=TRUE),
                                                                         tuneGrid=expand.grid(mtry=c(1,2),splitrule=c("gini"),min.node.size=c(200,250,300))) )
message <- utils::capture.output( DgivenGQ.Model.sample2 <- caret::train(stats::as.formula(paste(D, paste(G,Q,sep="+"), sep="~")), data=data[sample2,], method="ranger",
                                                                         trControl=caret::trainControl(method="boot", number=15, classProbs=TRUE),
                                                                         tuneGrid=expand.grid(mtry=c(1,2),splitrule=c("gini"),min.node.size=c(200,250,300))) )
data[,D] <- as.numeric(data[,D])-1

DgivenQ.Pred_G0 <- DgivenQ.Pred_G1 <- rep(NA, nrow(data))

pred_data <- data
pred_data[,G] <- 0
DgivenQ.Pred_G0[sample2] <- stats::predict(DgivenGQ.Model.sample1, newdata = pred_data[sample2,], type="prob")[,2]
DgivenQ.Pred_G0[sample1] <- stats::predict(DgivenGQ.Model.sample2, newdata = pred_data[sample1,], type="prob")[,2]

pred_data <- data
pred_data[,G] <- 1
DgivenQ.Pred_G1[sample2] <- stats::predict(DgivenGQ.Model.sample1, newdata = pred_data[sample2,], type="prob")[,2]
DgivenQ.Pred_G1[sample1] <- stats::predict(DgivenGQ.Model.sample2, newdata = pred_data[sample1,], type="prob")[,2]

# Estimate p_g(Q)=Pr(G=g | Q)
data[,G] <- as.factor(data[,G])
levels(data[,G]) <- c("G0","G1")  # necessary for caret implementation of ranger

message <- utils::capture.output( GgivenQ.Model.sample1 <- caret::train(stats::as.formula(paste(G, paste(Q,sep="+"), sep="~")), data=data[sample1,], method="ranger",
                                                                        trControl=caret::trainControl(method="boot", number=15, classProbs=TRUE),
                                                                        tuneGrid=expand.grid(mtry=1,splitrule=c("gini"),min.node.size=c(150,200))) )
message <- utils::capture.output( GgivenQ.Model.sample2 <- caret::train(stats::as.formula(paste(G, paste(Q,sep="+"), sep="~")), data=data[sample2,], method="ranger",
                                                                        trControl=caret::trainControl(method="boot", number=15, classProbs=TRUE),
                                                                        tuneGrid=expand.grid(mtry=1,splitrule=c("gini"),min.node.size=c(150,200))) )
data[,G] <- as.numeric(data[,G])-1

GgivenQ.Pred <- rep(NA, nrow(data))
GgivenQ.Pred[sample2] <- stats::predict(DgivenGQ.Model.sample1, newdata = data[sample2,], type="prob")[,2]
GgivenQ.Pred[sample1] <- stats::predict(DgivenGQ.Model.sample2, newdata = data[sample1,], type="prob")[,2]

cond_result_ranger <- cdgd1_manual(Y=Y,D=D,G=G,
                                   YgivenGXQ.Pred_D0=YgivenGXQ.Pred_D0,
                                   YgivenGXQ.Pred_D1=YgivenGXQ.Pred_D1,
                                   DgivenGXQ.Pred=DgivenGXQ.Pred,
                                   Y0givenQ.Pred_G0=Y0givenQ.Pred_G0,
                                   Y0givenQ.Pred_G1=Y0givenQ.Pred_G1,
                                   Y1givenQ.Pred_G0=Y1givenQ.Pred_G0,
                                   Y1givenQ.Pred_G1=Y1givenQ.Pred_G1,
                                   DgivenQ.Pred_G0=DgivenQ.Pred_G0,
                                   DgivenQ.Pred_G1=DgivenQ.Pred_G1,
                                   GgivenQ.Pred=GgivenQ.Pred,
                                   data,alpha=0.05)

### Bar plots
plotdf_c_pa_c <- as.data.frame(cbind(c("Total","Baseline","Cond prevalence","Cond effect","Cond selection","Q dist","Jackson"),cond_result_pa))
plotdf_c_nnet_c <- as.data.frame(cbind(c("Total","Baseline","Cond prevalence","Cond effect","Cond selection","Q dist","Jackson"),cond_result_nnet))
plotdf_c_gbm_c <- as.data.frame(cbind(c("Total","Baseline","Cond prevalence","Cond effect","Cond selection","Q dist","Jackson"),cond_result_gbm))
plotdf_c_ranger_c <- as.data.frame(cbind(c("Total","Baseline","Cond prevalence","Cond effect","Cond selection","Q dist","Jackson"),cond_result_ranger))
colnames(plotdf_c_pa_c)[1:2] <- colnames(plotdf_c_nnet_c)[1:2] <- colnames(plotdf_c_gbm_c)[1:2] <- colnames(plotdf_c_ranger_c)[1:2] <- c("Component","Estimate")

plotdf_c <- as.data.frame(rbind(plotdf_c_pa_c,plotdf_c_nnet_c,plotdf_c_gbm_c,plotdf_c_ranger_c))
plotdf_c$Model <- factor(c(rep("Param",7),rep("Nnet",7),rep("GBM",7),rep("Ranger",7)), levels=c("Nnet","GBM","Ranger","Param"))

plotdf_c <- plotdf_c[plotdf_c$Component!="Baseline" & plotdf_c$Component!="Total" & plotdf_c$Component!="Jackson",]
plotdf_c$Component <- factor(plotdf_c$Component, levels=c("Baseline","Cond prevalence","Cond effect","Cond selection","Q dist"), labels=c("Baseline","Cond prevalence","Cond effect","Cond selection","Q distribution"))

plot_c <- ggplot(plotdf_c, aes(x=Component, y=Estimate, fill=Model)) +
  geom_bar(stat="identity", position=position_dodge()) +
  geom_errorbar(aes(ymin=Estimate-qnorm(0.975)*se, ymax=Estimate+qnorm(0.975)*se), width=.2, linewidth=0.4,
                position=position_dodge(.9))+
  scale_fill_brewer(palette="Paired") + theme_minimal() +
  geom_hline(yintercept=cond_result_pa$point[1], linetype="dashed") +
  geom_hline(yintercept=0) +
  annotate("text", x=3.15, y=0.19, label= "Total disparity", size=3.3) +
  coord_cartesian(ylim=c(-0.08,0.23), expand=FALSE) +
  scale_y_continuous(breaks=c(-0.05,0,0.05,0.1,0.15,0.2)) +
  theme(text=element_text(size=11))

ggsave(paste("/Users/Ang/Desktop/Research/Causal_decomposition/conditional_",Sys.Date(),".jpg", sep=""), plot_c, width=5, height=3.5)


##### Generate Latex tables

rd <- function(x) {format(round(x, 3), nsmall = 3)}
irl <- function(x,y,z) {
  c(interleave(rd(x), paste("(", paste(rd(y), rd(z), sep=", "), ")", sep="")))
}

### Table A2.
tableA2 <- cbind(c("Total","","Baseline","","Prevalence","","Effect","","Selection","","Jackson reduction",""),
                 rbind(cbind(irl(result_gbm$results$point,result_gbm$results$CI_lower,result_gbm$results$CI_upper),
                             irl(result_nnet$results$point,result_nnet$results$CI_lower,result_nnet$results$CI_upper),
                             irl(result_ranger$results$point,result_ranger$results$CI_lower,result_ranger$results$CI_upper),
                             irl(result_pa$results$point,result_pa$results$CI_lower,result_pa$results$CI_upper)),
                       cbind(irl(result_gbm$results_specific$point[13],result_gbm$results_specific$CI_lower[13],result_gbm$results_specific$CI_upper[13]),
                             irl(result_nnet$results_specific$point[13],result_nnet$results_specific$CI_lower[13],result_nnet$results_specific$CI_upper[13]),
                             irl(result_ranger$results_specific$point[13],result_ranger$results_specific$CI_lower[13],result_ranger$results_specific$CI_upper[13]),
                             irl(result_pa$results_specific$point[13],result_pa$results_specific$CI_lower[13],result_pa$results_specific$CI_upper[13]))
                 ))
xtable(tableA2)

# Instruction to ChatGPT: Please remove the first column and the spaces between parentheses and numbers from this latex table

### Table A3
tableA3 <- cbind(c("Total","","Baseline","","Conditional prevalence","","Conditional effect","","Conditional selection","","Q distribution","","Conditional Jackson reduction",""),
                 irl(cond_result_gbm$point,cond_result_gbm$CI_lower,cond_result_gbm$CI_upper),
                 irl(cond_result_nnet$point,cond_result_nnet$CI_lower,cond_result_nnet$CI_upper),
                 irl(cond_result_ranger$point,cond_result_ranger$CI_lower,cond_result_ranger$CI_upper),
                 irl(cond_result_pa$point,cond_result_pa$CI_lower,cond_result_pa$CI_upper))
xtable(tableA3)

cbind(cond_result_gbm[,c("point","p_value")],
      cond_result_nnet[,c("point","p_value")],
      cond_result_ranger[,c("point","p_value")],
      cond_result_pa[,c("point","p_value")])

### Table A.1
rd(result_gbm$results_specific[3:12,c("point","CI_lower","CI_upper")])
rd(result_nnet$results_specific[3:12,c("point","CI_lower","CI_upper")])
rd(result_ranger$results_specific[3:12,c("point","CI_lower","CI_upper")])
rd(result_pa$results_specific[3:12,c("point","CI_lower","CI_upper")])
