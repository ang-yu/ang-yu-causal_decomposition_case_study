library("caret")
library("nnet")
library("gbm")
library("ranger")
library("gdata")
library("xtable")
library("ggplot2")
library("gridExtra")

rm(list=ls(all=TRUE))

data <- readRDS("/Users/Ang/Desktop/Research/Causal_decomposition/Data/data_cleaned.rds")

data$gender <- as.numeric(data$gender)-1

data$parental_presence <- as.numeric(data$parental_presence)-1

data$n_sib <- as.numeric(data$n_sib)-1

data$urban <- as.numeric(data$urban)-1

data$edu_exp <- as.numeric(data$edu_exp)-2
data$edu_exp[data$edu_exp==-1] <- 0

data$age <- as.numeric(data$age)-1

data$friend_edu_exp <- as.numeric(data$friend_edu_exp)-2
data$friend_edu_exp[data$friend_edu_exp==-1] <- 0

data$foreign_lang <- as.numeric(data$foreign_lang)-1

data$SMSA1 <- NA
data$SMSA1[data$SMSA==0 & !is.na(data$SMSA)] <- 1
data$SMSA1[data$SMSA!=0 & !is.na(data$SMSA)] <- 0
data$SMSA2 <- NA
data$SMSA2[data$SMSA==1 & !is.na(data$SMSA)] <- 1
data$SMSA2[data$SMSA!=1 & !is.na(data$SMSA)] <- 0
data$SMSA3 <- NA
data$SMSA3[data$SMSA==2 & !is.na(data$SMSA)] <- 1
data$SMSA3[data$SMSA!=2 & !is.na(data$SMSA)] <- 0
data$SMSA4 <- NA
data$SMSA4[data$SMSA==3 & !is.na(data$SMSA)] <- 1
data$SMSA4[data$SMSA!=3 & !is.na(data$SMSA)] <- 0

data$mother_seperate <- as.numeric(data$mother_seperate)-1

data$school_satis1 <- NA
data$school_satis1[(data$school_satisfaction==1 | data$school_satisfaction==2) & !is.na(data$school_satisfaction)] <- 1
data$school_satis1[data$school_satisfaction!=1 & data$school_satisfaction!=2 & !is.na(data$school_satisfaction)] <- 0
data$school_satis2 <- NA
data$school_satis2[data$school_satisfaction==3 & !is.na(data$school_satisfaction)] <- 1
data$school_satis2[data$school_satisfaction!=3 & !is.na(data$school_satisfaction)] <- 0
data$school_satis3 <- NA
data$school_satis3[data$school_satisfaction==4 & !is.na(data$school_satisfaction)] <- 1
data$school_satis3[data$school_satisfaction!=4 & !is.na(data$school_satisfaction)] <- 0

data$region1 <- NA
data$region1[data$region==1 & !is.na(data$region)] <- 1
data$region1[data$region!=1 & !is.na(data$region)] <- 0
data$region2 <- NA
data$region2[data$region==2 & !is.na(data$region)] <- 1
data$region2[data$region!=2 & !is.na(data$region)] <- 0
data$region3 <- NA
data$region3[data$region==3 & !is.na(data$region)] <- 1
data$region3[data$region!=3 & !is.na(data$region)] <- 0
data$region4 <- NA
data$region4[data$region==4 & !is.na(data$region)] <- 1
data$region4[data$region!=4 & !is.na(data$region)] <- 0

data$m_work <- as.numeric(data$m_work)-1

data$race1 <- NA
data$race1[data$race=="Other" & !is.na(data$race)] <- 1
data$race1[data$race!="Other" & !is.na(data$race)] <- 0
data$race2 <- NA
data$race2[data$race=="Black" & !is.na(data$race)] <- 1
data$race2[data$race!="Black" & !is.na(data$race)] <- 0
data$race3 <- NA
data$race3[data$race=="Hispanic" & !is.na(data$race)] <- 1
data$race3[data$race!="Hispanic" & !is.na(data$race)] <- 0

data$completion <- as.numeric(data$completion)-1

data$pincome_1 <- NA
data$pincome_1[data$parental_income_rank>=0.60 & !is.na(data$parental_income_rank)] <- 1
data$pincome_1[data$parental_income_rank<0.60 & !is.na(data$parental_income_rank)] <- 0

data$pincome_2 <- NA
data$pincome_2[data$parental_income_rank<=0.40 & !is.na(data$parental_income_rank)] <- 1
data$pincome_2[data$parental_income_rank>0.40 & !is.na(data$parental_income_rank)] <- 0

data <- data[!is.na(data$pincome_1) & (data$pincome_1==1 | data$pincome_2==1), ]
colMeans(is.na(data))
data <- na.omit(data)   # from 3295 to 2008

covariates <- c("AFQT","gender","medu","parental_presence","n_sib","urban","edu_exp","age",
                "friend_edu_exp","rotter_score","rosenberg_irt_score","foreign_lang","m_work",
                "SMSA2","SMSA3","SMSA4","mother_seperate","school_satis2","school_satis3",
                "region2","region3","region4","race2","race3","parental_income_rank")

Y="adult_income_rank"
D="completion"
G="pincome_1"
Q="AFQT"
X=covariates[!covariates%in%"AFQT"]


##### estimate E[ E(D|Q,a)|b ]
### parametric
DgivenGQ.Model <- glm(as.formula(paste(D, paste(paste(G,Q,sep="*"),collapse="+"), sep="~")), data=data, family=binomial(link="logit"))

pred_data <- data[data[,G]==0,]
pred_data[,G] <- 1
pred_para <- mean( predict(DgivenGQ.Model, newdata = pred_data, type="response") )

### nnet
data[,D] <- as.factor(data[,D])
levels(data[,D]) <- c("D0","D1")  # necessary for caret implementation of ranger

set.seed(1)
DgivenGQ.Model <- caret::train(stats::as.formula(paste(D, paste(G,paste(Q,collapse="+"),sep="+"), sep="~")), data=data, method="nnet",
                                                                           preProc=c("center","scale"), trControl=caret::trainControl(method="cv"), linout=FALSE )

pred_data <- data[data[,G]==0,]
pred_data[,G] <- 1
pred_nnet <- mean( predict(DgivenGQ.Model, newdata = pred_data, type="prob")[,2] )

### gbm
DgivenGQ.Model <- caret::train(stats::as.formula(paste(D, paste(G,paste(Q,collapse="+"),sep="+"), sep="~")), data=data, method="gbm",
                                                                           trControl=caret::trainControl(method="cv")) 

pred_data <- data[data[,G]==0,]
pred_data[,G] <- 1
pred_gbm <- mean( predict(DgivenGQ.Model, newdata = pred_data, type="prob")[,2] )

### ranger
DgivenGQ.Model <- caret::train(stats::as.formula(paste(D, paste(G,paste(Q,collapse="+"),sep="+"), sep="~")), data=data, method="ranger",
                                                                           trControl=caret::trainControl(method="cv", classProbs=TRUE)) 

pred_data <- data[data[,G]==0,]
pred_data[,G] <- 1
pred_ranger <- mean( predict(DgivenGQ.Model, newdata = pred_data, type="prob")[,2] )

data[,D] <- as.numeric(data[,D])-1
##### get the benchmark \rho_{1b} and \rho_{2b}
C <- X[!X%in%"edu_exp"]

rho1_exp <- coef( lm( as.formula(paste("edu_exp", paste(c(D,C), collapse="+"), sep="~")) , data=data[data[,G]==0, ] ) )[2]
rho2_exp <- coef( lm( as.formula(paste(Y, paste(c(D,X), collapse="+"), sep="~")) , data=data[data[,G]==0, ] ) )[8]

rho1_seq <- seq(0, 4*rho1_exp, length.out=100)
rho2_seq <- seq(0, 4*rho2_exp, length.out=100)
contour_data <- as.data.frame(expand.grid(rho1 = rho1_seq, rho2 = rho2_seq))
### plot for nnet
contour_data$prevalence <- 0.031-contour_data$rho1*contour_data$rho2*(mean(data[data[,G]==1, D]) - mean(data[data[,G]==0, D]))
contour_data$cond_prevalence <- 0.010-contour_data$rho1*contour_data$rho2*(mean(pred_nnet) - mean(data[data[,G]==0, D]))

nnet_prevalence <- ggplot(contour_data, aes(x = rho1, y = rho2, z = prevalence)) +
  geom_contour(aes(colour = factor(after_stat(level))), breaks = c(0,0.009,0.018,0.027)) +
  geom_point(aes(x = rho1_exp, y = rho2_exp), color = "blue") +
  annotate("text", x=rho1_exp, y=rho2_exp+0.01, 
           label = "(0.27,0.05)", size=3) +
  geom_point(aes(x = rho1_exp*2, y = rho2_exp*2), color = "red") +
  annotate("text", x=rho1_exp*2, y=rho2_exp*2+0.01, 
           label = "(0.54,0.10)", size=3) +
  geom_point(aes(x = rho1_exp*3, y = rho2_exp*3), color = "red") +
  annotate("text", x=rho1_exp*3, y=rho2_exp*3+0.01, 
           label = "(0.81,0.15)", size=3) +
  labs(title = "(a) Neural networks (original estimate=0.031)", x="rho_1b", y="rho_2b",) +
  scale_color_manual(values = c("#a6bddb", "#9ecae1", "#3182bd", "#08519c"), name = "Debiased estimate") +
  theme_minimal()

nnet_cond_prevalence <- ggplot(contour_data, aes(x = rho1, y = rho2, z = cond_prevalence)) +
  geom_contour(aes(colour = factor(after_stat(level))), breaks = c(0,0.002,0.004,0.006)) +
  geom_point(aes(x = rho1_exp, y = rho2_exp), color = "blue") +
  annotate("text", x=rho1_exp+0.05, y=rho2_exp+0.01, 
           label = "(0.27,0.05)", size=3) +
  geom_point(aes(x = rho1_exp*2, y = rho2_exp*2), color = "red") +
  annotate("text", x=rho1_exp*2, y=rho2_exp*2+0.01, 
           label = "(0.54,0.10)", size=3) +
  geom_point(aes(x = rho1_exp*3, y = rho2_exp*3), color = "red") +
  annotate("text", x=rho1_exp*3, y=rho2_exp*3+0.01, 
           label = "(0.81,0.15)", size=3) +
  labs(title = "(a) Neural networks (original estimate=0.010)", x="rho_1b", y="rho_2b",) +
  scale_color_manual(values = c("#a6bddb", "#9ecae1", "#3182bd", "#08519c"), name = "Debiased estimate") +
  theme_minimal()

### plot for gbm  
contour_data$prevalence <- 0.028-contour_data$rho1*contour_data$rho2*(mean(data[data[,G]==1, D]) - mean(data[data[,G]==0, D]))
contour_data$cond_prevalence <- 0.007-contour_data$rho1*contour_data$rho2*(mean(pred_gbm) - mean(data[data[,G]==0, D]))

gbm_prevalence <- ggplot(contour_data, aes(x = rho1, y = rho2, z = prevalence)) +
  geom_contour(aes(colour = factor(after_stat(level))), breaks = c(0,0.009,0.018,0.027)) +
  geom_point(aes(x = rho1_exp, y = rho2_exp), color = "blue") +
  annotate("text", x=rho1_exp, y=rho2_exp+0.01, 
           label = "(0.27,0.05)", size=3) +
  geom_point(aes(x = rho1_exp*2, y = rho2_exp*2), color = "red") +
  annotate("text", x=rho1_exp*2, y=rho2_exp*2+0.01, 
           label = "(0.54,0.10)", size=3) +
  geom_point(aes(x = rho1_exp*3, y = rho2_exp*3), color = "red") +
  annotate("text", x=rho1_exp*3, y=rho2_exp*3+0.01, 
           label = "(0.81,0.15)", size=3) +
  labs(title = "(b) GBM (original estimate=0.028)", x="rho_1b", y="rho_2b",) +
  scale_color_manual(values = c("#a6bddb", "#9ecae1", "#3182bd", "#08519c"), name = "Debiased estimate") +
  theme_minimal()

gbm_cond_prevalence <- ggplot(contour_data, aes(x = rho1, y = rho2, z = cond_prevalence)) +
  geom_contour(aes(colour = factor(after_stat(level))), breaks = c(0,0.002,0.004,0.006)) +
  geom_point(aes(x = rho1_exp, y = rho2_exp), color = "blue") +
  annotate("text", x=rho1_exp+0.03, y=rho2_exp+0.01, 
           label = "(0.27,0.05)", size=3) +
  geom_point(aes(x = rho1_exp*2, y = rho2_exp*2), color = "red") +
  annotate("text", x=rho1_exp*2, y=rho2_exp*2+0.01, 
           label = "(0.54,0.10)", size=3) +
  geom_point(aes(x = rho1_exp*3, y = rho2_exp*3), color = "red") +
  annotate("text", x=rho1_exp*3, y=rho2_exp*3+0.01, 
           label = "(0.81,0.15)", size=3) +
  labs(title = "(b) GBM (original estimate=0.007)", x="rho_1b", y="rho_2b",) +
  scale_color_manual(values = c("#a6bddb", "#9ecae1", "#3182bd", "#08519c"), name = "Debiased estimate") +
  theme_minimal()

### plot for ranger  
contour_data$prevalence <- 0.029-contour_data$rho1*contour_data$rho2*(mean(data[data[,G]==1, D]) - mean(data[data[,G]==0, D]))
contour_data$cond_prevalence <- 0.013-contour_data$rho1*contour_data$rho2*(mean(pred_ranger) - mean(data[data[,G]==0, D]))

ranger_prevalence <- ggplot(contour_data, aes(x = rho1, y = rho2, z = prevalence)) +
  geom_contour(aes(colour = factor(after_stat(level))), breaks = c(0,0.009,0.018,0.027)) +
  geom_point(aes(x = rho1_exp, y = rho2_exp), color = "blue") +
  annotate("text", x=rho1_exp, y=rho2_exp+0.01, 
           label = "(0.27,0.05)", size=3) +
  geom_point(aes(x = rho1_exp*2, y = rho2_exp*2), color = "red") +
  annotate("text", x=rho1_exp*2, y=rho2_exp*2+0.01, 
           label = "(0.54,0.10)", size=3) +
  geom_point(aes(x = rho1_exp*3, y = rho2_exp*3), color = "red") +
  annotate("text", x=rho1_exp*3, y=rho2_exp*3+0.01, 
           label = "(0.81,0.15)", size=3) +
  labs(title = "(c) Random forests (original estimate=0.029)", x="rho_1b", y="rho_2b",) +
  scale_color_manual(values = c("#a6bddb", "#9ecae1", "#3182bd", "#08519c"), name = "Debiased estimate") +
  theme_minimal()

ranger_cond_prevalence <- ggplot(contour_data, aes(x = rho1, y = rho2, z = cond_prevalence)) +
  geom_contour(aes(colour = factor(after_stat(level))), breaks = c(0,0.002,0.004,0.006)) +
  geom_point(aes(x = rho1_exp, y = rho2_exp), color = "blue") +
  annotate("text", x=rho1_exp+0.05, y=rho2_exp+0.01, 
           label = "(0.27,0.05)", size=3) +
  geom_point(aes(x = rho1_exp*2, y = rho2_exp*2), color = "red") +
  annotate("text", x=rho1_exp*2, y=rho2_exp*2+0.01, 
           label = "(0.54,0.10)", size=3) +
  geom_point(aes(x = rho1_exp*3, y = rho2_exp*3), color = "red") +
  annotate("text", x=rho1_exp*3, y=rho2_exp*3+0.01, 
           label = "(0.81,0.15)", size=3) +
  labs(title = "(c) Random forests (original estimate=0.013)", x="rho_1b", y="rho_2b",) +
  scale_color_manual(values = c("#a6bddb", "#9ecae1", "#3182bd", "#08519c"), name = "Debiased estimate") +
  theme_minimal()

### plot for parametric  
contour_data$prevalence <- 0.036-contour_data$rho1*contour_data$rho2*(mean(data[data[,G]==1, D]) - mean(data[data[,G]==0, D]))
contour_data$cond_prevalence <- 0.009-contour_data$rho1*contour_data$rho2*(mean(pred_para) - mean(data[data[,G]==0, D]))

para_prevalence <- ggplot(contour_data, aes(x = rho1, y = rho2, z = prevalence)) +
  geom_contour(aes(colour = factor(after_stat(level))), breaks = c(0,0.009,0.018,0.027)) +
  geom_point(aes(x = rho1_exp, y = rho2_exp), color = "blue") +
  annotate("text", x=rho1_exp, y=rho2_exp+0.01, 
           label = "(0.27,0.05)", size=3) +
  geom_point(aes(x = rho1_exp*2, y = rho2_exp*2), color = "red") +
  annotate("text", x=rho1_exp*2, y=rho2_exp*2+0.01, 
           label = "(0.54,0.10)", size=3) +
  geom_point(aes(x = rho1_exp*3, y = rho2_exp*3), color = "red") +
  annotate("text", x=rho1_exp*3, y=rho2_exp*3+0.01, 
           label = "(0.81,0.15)", size=3) +
  labs(title = "(d) Parametric models (original estimate=0.036)", x="rho_1b", y="rho_2b",) +
  scale_color_manual(values = c("#a6bddb", "#9ecae1", "#3182bd", "#08519c"), name = "Debiased estimate") +
  theme_minimal()

para_cond_prevalence <- ggplot(contour_data, aes(x = rho1, y = rho2, z = cond_prevalence)) +
  geom_contour(aes(colour = factor(after_stat(level))), breaks = c(0,0.002,0.004,0.006)) +
  geom_point(aes(x = rho1_exp, y = rho2_exp), color = "blue") +
  annotate("text", x=rho1_exp+0.03, y=rho2_exp+0.01, 
           label = "(0.27,0.05)", size=3) +
  geom_point(aes(x = rho1_exp*2, y = rho2_exp*2), color = "red") +
  annotate("text", x=rho1_exp*2, y=rho2_exp*2+0.01, 
           label = "(0.54,0.10)", size=3) +
  geom_point(aes(x = rho1_exp*3, y = rho2_exp*3), color = "red") +
  annotate("text", x=rho1_exp*3, y=rho2_exp*3+0.01, 
           label = "(0.81,0.15)", size=3) +
  labs(title = "(d) Parametric models (original estimate=0.009)", x="rho_1b", y="rho_2b",) +
  scale_color_manual(values = c("#a6bddb", "#9ecae1", "#3182bd", "#08519c"), name = "Debiased estimate") +
  theme_minimal()

all_unconditional <- grid.arrange(nnet_prevalence, gbm_prevalence, ranger_prevalence, para_prevalence, ncol=2)
ggsave(paste("/Users/Ang/Desktop/Research/Causal_decomposition/sensitivity_unconditional_",Sys.Date(),".jpg", sep=""), all_unconditional, width=10, height=5)

all_conditional <- grid.arrange(nnet_cond_prevalence, gbm_cond_prevalence, ranger_cond_prevalence, para_cond_prevalence, ncol=2)
ggsave(paste("/Users/Ang/Desktop/Research/Causal_decomposition/sensitivity_conditional_",Sys.Date(),".jpg", sep=""), all_conditional, width=10, height=5)

