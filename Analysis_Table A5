##### Table A5


library("caret")
library("nnet")
library("gbm")
library("ranger")
library("gdata")
library("xtable")

library("cdgd")

rm(list=ls(all=TRUE))

data <- readRDS("/Users/Ang/Desktop/Research/Causal_decomposition/Data/data_cleaned.rds")

data$gender <- as.numeric(data$gender)-1

data$parental_presence <- as.numeric(data$parental_presence)-1

data$n_sib <- as.numeric(data$n_sib)-1

data$urban <- as.numeric(data$urban)-1

data$edu_exp <- as.numeric(data$edu_exp)-2
data$edu_exp[data$edu_exp==-1] <- 0

data$age <- as.numeric(data$age)-1

data$friend_edu_exp <- as.numeric(data$friend_edu_exp)-2
data$friend_edu_exp[data$friend_edu_exp==-1] <- 0

data$foreign_lang <- as.numeric(data$foreign_lang)-1

data$SMSA1 <- NA
data$SMSA1[data$SMSA==0 & !is.na(data$SMSA)] <- 1
data$SMSA1[data$SMSA!=0 & !is.na(data$SMSA)] <- 0
data$SMSA2 <- NA
data$SMSA2[data$SMSA==1 & !is.na(data$SMSA)] <- 1
data$SMSA2[data$SMSA!=1 & !is.na(data$SMSA)] <- 0
data$SMSA3 <- NA
data$SMSA3[data$SMSA==2 & !is.na(data$SMSA)] <- 1
data$SMSA3[data$SMSA!=2 & !is.na(data$SMSA)] <- 0
data$SMSA4 <- NA
data$SMSA4[data$SMSA==3 & !is.na(data$SMSA)] <- 1
data$SMSA4[data$SMSA!=3 & !is.na(data$SMSA)] <- 0

data$mother_seperate <- as.numeric(data$mother_seperate)-1

data$school_satis1 <- NA
data$school_satis1[(data$school_satisfaction==1 | data$school_satisfaction==2) & !is.na(data$school_satisfaction)] <- 1
data$school_satis1[data$school_satisfaction!=1 & data$school_satisfaction!=2 & !is.na(data$school_satisfaction)] <- 0
data$school_satis2 <- NA
data$school_satis2[data$school_satisfaction==3 & !is.na(data$school_satisfaction)] <- 1
data$school_satis2[data$school_satisfaction!=3 & !is.na(data$school_satisfaction)] <- 0
data$school_satis3 <- NA
data$school_satis3[data$school_satisfaction==4 & !is.na(data$school_satisfaction)] <- 1
data$school_satis3[data$school_satisfaction!=4 & !is.na(data$school_satisfaction)] <- 0

data$region1 <- NA
data$region1[data$region==1 & !is.na(data$region)] <- 1
data$region1[data$region!=1 & !is.na(data$region)] <- 0
data$region2 <- NA
data$region2[data$region==2 & !is.na(data$region)] <- 1
data$region2[data$region!=2 & !is.na(data$region)] <- 0
data$region3 <- NA
data$region3[data$region==3 & !is.na(data$region)] <- 1
data$region3[data$region!=3 & !is.na(data$region)] <- 0
data$region4 <- NA
data$region4[data$region==4 & !is.na(data$region)] <- 1
data$region4[data$region!=4 & !is.na(data$region)] <- 0

data$m_work <- as.numeric(data$m_work)-1

data$race1 <- NA
data$race1[data$race=="Other" & !is.na(data$race)] <- 1
data$race1[data$race!="Other" & !is.na(data$race)] <- 0
data$race2 <- NA
data$race2[data$race=="Black" & !is.na(data$race)] <- 1
data$race2[data$race!="Black" & !is.na(data$race)] <- 0
data$race3 <- NA
data$race3[data$race=="Hispanic" & !is.na(data$race)] <- 1
data$race3[data$race!="Hispanic" & !is.na(data$race)] <- 0

data$completion <- as.numeric(data$completion)-1

data$pincome_1 <- NA
data$pincome_1[data$parental_income_rank>=0.60 & !is.na(data$parental_income_rank)] <- 1
data$pincome_1[data$parental_income_rank<0.60 & !is.na(data$parental_income_rank)] <- 0

data$pincome_2 <- NA
data$pincome_2[data$parental_income_rank<=0.40 & !is.na(data$parental_income_rank)] <- 1
data$pincome_2[data$parental_income_rank>0.40 & !is.na(data$parental_income_rank)] <- 0

data <- data[!is.na(data$pincome_1) & (data$pincome_1==1 | data$pincome_2==1), ]
colMeans(is.na(data))
data <- na.omit(data)   # from 3295 to 2008

covariates <- c("AFQT","gender","medu","parental_presence","n_sib","urban","edu_exp","age",
                "friend_edu_exp","rotter_score","rosenberg_irt_score","foreign_lang","m_work",
                "SMSA2","SMSA3","SMSA4","mother_seperate","school_satis2","school_satis3",
                "region2","region3","region4","race2","race3","parental_income_rank")


Y="adult_income_rank"
D="completion"
G="pincome_1"
Q="AFQT"
X=covariates[!covariates%in%"AFQT"]

### ranger + parametric

set.seed(1)
# estimate the nuisance functions with cross-fitting
sample1 <- sample(nrow(data), floor(nrow(data)/2), replace=FALSE)
sample2 <- setdiff(1:nrow(data), sample1)

# outcome regression model
message <- utils::capture.output( YgivenDGXQ.Model.sample1 <- caret::train(stats::as.formula(paste(Y, paste(D,G,Q,paste(X,collapse="+"),sep="+"), sep="~")), data=data[sample1,], method="ranger",
                                                                           trControl=caret::trainControl(method="boot", number=15),
                                                                           tuneGrid=expand.grid(mtry=c(10,15,20),splitrule=c("variance"),min.node.size=c(200,250,300))) )
message <- utils::capture.output( YgivenDGXQ.Model.sample2 <- caret::train(stats::as.formula(paste(Y, paste(D,G,Q,paste(X,collapse="+"),sep="+"), sep="~")), data=data[sample2,], method="ranger",
                                                                           trControl=caret::trainControl(method="boot", number=15),
                                                                           tuneGrid=expand.grid(mtry=c(10,15,20),splitrule=c("variance"),min.node.size=c(200,250,300))) )

# propensity score model
data[,D] <- as.factor(data[,D])
levels(data[,D]) <- c("D0","D1")  # necessary for caret implementation of ranger

message <- utils::capture.output( DgivenGXQ.Model.sample1 <- caret::train(stats::as.formula(paste(D, paste(G,Q,paste(X,collapse="+"),sep="+"), sep="~")), data=data[sample1,], method="ranger",
                                                                          trControl=caret::trainControl(method="boot", number=15, classProbs=TRUE),
                                                                          tuneGrid=expand.grid(mtry=c(10,15,20),splitrule=c("gini"),min.node.size=c(200,250,300))) )
message <- utils::capture.output( DgivenGXQ.Model.sample2 <- caret::train(stats::as.formula(paste(D, paste(G,Q,paste(X,collapse="+"),sep="+"), sep="~")), data=data[sample2,], method="ranger",
                                                                          trControl=caret::trainControl(method="boot", number=15, classProbs=TRUE),
                                                                          tuneGrid=expand.grid(mtry=c(10,15,20),splitrule=c("gini"),min.node.size=c(200,250,300))) )
data[,D] <- as.numeric(data[,D])-1

# cross-fitted predictions
YgivenGXQ.Pred_D0 <- YgivenGXQ.Pred_D1 <- DgivenGXQ.Pred <- rep(NA, nrow(data))

pred_data <- data
pred_data[,D] <- 0
YgivenGXQ.Pred_D0[sample2] <- stats::predict(YgivenDGXQ.Model.sample1, newdata = pred_data[sample2,])
YgivenGXQ.Pred_D0[sample1] <- stats::predict(YgivenDGXQ.Model.sample2, newdata = pred_data[sample1,])

pred_data <- data
pred_data[,D] <- 1
YgivenGXQ.Pred_D1[sample2] <- stats::predict(YgivenDGXQ.Model.sample1, newdata = pred_data[sample2,])
YgivenGXQ.Pred_D1[sample1] <- stats::predict(YgivenDGXQ.Model.sample2, newdata = pred_data[sample1,])

pred_data <- data
DgivenGXQ.Pred[sample2] <- stats::predict(DgivenGXQ.Model.sample1, newdata = pred_data[sample2,], type="prob")[,2]
DgivenGXQ.Pred[sample1] <- stats::predict(DgivenGXQ.Model.sample2, newdata = pred_data[sample1,], type="prob")[,2]

# Estimate E(Y_d | Q,g)
# IPOs for modelling E(Y_d | Q,g)
IPO_D0 <- (1-data[,D])/(1-DgivenGXQ.Pred)/mean((1-data[,D])/(1-DgivenGXQ.Pred))*(data[,Y]-YgivenGXQ.Pred_D0) + YgivenGXQ.Pred_D0
IPO_D1 <- data[,D]/DgivenGXQ.Pred/mean(data[,D]/DgivenGXQ.Pred)*(data[,Y]-YgivenGXQ.Pred_D1) + YgivenGXQ.Pred_D1

data$Q_squared <- data[,Q]^2   # add a squared term for Q

data_temp <- data[,c(G,Q,"Q_squared")]
data_temp$IPO_D0 <- IPO_D0
data_temp$IPO_D1 <- IPO_D1

Y0givenGQ.Model <- stats::lm(stats::as.formula(paste("IPO_D0", paste(paste(G,c(Q,"Q_squared"),sep="*"),collapse="+"), sep="~")), data=data_temp)
Y1givenGQ.Model <- stats::lm(stats::as.formula(paste("IPO_D1", paste(paste(G,c(Q,"Q_squared"),sep="*"),collapse="+"), sep="~")), data=data_temp)

Y0givenQ.Pred_G0 <- Y0givenQ.Pred_G1 <- Y1givenQ.Pred_G0 <- Y1givenQ.Pred_G1 <- rep(NA, nrow(data))

pred_data <- data
pred_data[,G] <- 1
Y0givenQ.Pred_G1 <- stats::predict(Y0givenGQ.Model, newdata = pred_data) 
Y1givenQ.Pred_G1 <- stats::predict(Y1givenGQ.Model, newdata = pred_data)

pred_data <- data
pred_data[,G] <- 0
Y0givenQ.Pred_G0 <- stats::predict(Y0givenGQ.Model, newdata = pred_data)
Y1givenQ.Pred_G0 <- stats::predict(Y1givenGQ.Model, newdata = pred_data)

# Estimate E(D | Q,g')
DgivenGQ.Model <- stats::glm(stats::as.formula(paste(D, paste(paste(G,c(Q,"Q_squared"),sep="*"),collapse="+"), sep="~")), data=data, family=stats::binomial(link="logit"))

DgivenQ.Pred_G0 <- DgivenQ.Pred_G1 <- rep(NA, nrow(data))

pred_data <- data
pred_data[,G] <- 0
DgivenQ.Pred_G0 <- stats::predict(DgivenGQ.Model, newdata = pred_data, type="response")

pred_data <- data
pred_data[,G] <- 1
DgivenQ.Pred_G1 <- stats::predict(DgivenGQ.Model, newdata = pred_data, type="response")

# Estimate p_g(Q)=Pr(G=g | Q)
data[,G] <- as.factor(data[,G])
levels(data[,G]) <- c("G0","G1")  # necessary for caret implementation of ranger

message <- utils::capture.output( GgivenQ.Model.sample1 <- caret::train(stats::as.formula(paste(G, paste(Q,sep="+"), sep="~")), data=data[sample1,], method="ranger",
                                                                        trControl=caret::trainControl(method="boot", number=15, classProbs=TRUE),
                                                                        tuneGrid=expand.grid(mtry=1,splitrule=c("gini"),min.node.size=c(150,200))) )
message <- utils::capture.output( GgivenQ.Model.sample2 <- caret::train(stats::as.formula(paste(G, paste(Q,sep="+"), sep="~")), data=data[sample2,], method="ranger",
                                                                        trControl=caret::trainControl(method="boot", number=15, classProbs=TRUE),
                                                                        tuneGrid=expand.grid(mtry=1,splitrule=c("gini"),min.node.size=c(150,200))) )
data[,G] <- as.numeric(data[,G])-1

GgivenQ.Pred <- rep(NA, nrow(data))
GgivenQ.Pred[sample2] <- stats::predict(GgivenQ.Model.sample1, newdata = data[sample2,], type="prob")[,2]
GgivenQ.Pred[sample1] <- stats::predict(GgivenQ.Model.sample2, newdata = data[sample1,], type="prob")[,2]

cond_result_ranger <- cdgd1_manual(Y=Y,D=D,G=G,
                                   YgivenGXQ.Pred_D0=YgivenGXQ.Pred_D0,
                                   YgivenGXQ.Pred_D1=YgivenGXQ.Pred_D1,
                                   DgivenGXQ.Pred=DgivenGXQ.Pred,
                                   Y0givenQ.Pred_G0=Y0givenQ.Pred_G0,
                                   Y0givenQ.Pred_G1=Y0givenQ.Pred_G1,
                                   Y1givenQ.Pred_G0=Y1givenQ.Pred_G0,
                                   Y1givenQ.Pred_G1=Y1givenQ.Pred_G1,
                                   DgivenQ.Pred_G0=DgivenQ.Pred_G0,
                                   DgivenQ.Pred_G1=DgivenQ.Pred_G1,
                                   GgivenQ.Pred=GgivenQ.Pred,
                                   data,alpha=0.05)



### nnet + parametric

set.seed(1)
# estimate the nuisance functions with cross-fitting
sample1 <- sample(nrow(data), floor(nrow(data)/2), replace=FALSE)
sample2 <- setdiff(1:nrow(data), sample1)

# outcome regression model
message <- utils::capture.output( YgivenDGXQ.Model.sample1 <- caret::train(stats::as.formula(paste(Y, paste(D,G,paste(Q,collapse="+"),paste(X,collapse="+"),sep="+"), sep="~")), data=data[sample1,], method="nnet",
                                                                           preProc=c("center","scale"), trControl=caret::trainControl(method="cv"), linout=TRUE ))
message <- utils::capture.output( YgivenDGXQ.Model.sample2 <- caret::train(stats::as.formula(paste(Y, paste(D,G,paste(Q,collapse="+"),paste(X,collapse="+"),sep="+"), sep="~")), data=data[sample2,], method="nnet",
                                                                           preProc=c("center","scale"), trControl=caret::trainControl(method="cv"), linout=TRUE ))

# propensity score model
data[,D] <- as.factor(data[,D])
levels(data[,D]) <- c("D0","D1")  # necessary for caret implementation of ranger

message <- utils::capture.output( DgivenGXQ.Model.sample1 <- caret::train(stats::as.formula(paste(D, paste(G,paste(Q,collapse="+"),paste(X,collapse="+"),sep="+"), sep="~")), data=data[sample1,], method="nnet",
                                                                          preProc=c("center","scale"), trControl=caret::trainControl(method="cv"), linout=FALSE ))
message <- utils::capture.output( DgivenGXQ.Model.sample2 <- caret::train(stats::as.formula(paste(D, paste(G,paste(Q,collapse="+"),paste(X,collapse="+"),sep="+"), sep="~")), data=data[sample2,], method="nnet",
                                                                          preProc=c("center","scale"), trControl=caret::trainControl(method="cv"), linout=FALSE ))
data[,D] <- as.numeric(data[,D])-1

# cross-fitted predictions
YgivenGXQ.Pred_D0 <- YgivenGXQ.Pred_D1 <- DgivenGXQ.Pred <- rep(NA, nrow(data))

pred_data <- data
pred_data[,D] <- 0
YgivenGXQ.Pred_D0[sample2] <- stats::predict(YgivenDGXQ.Model.sample1, newdata = pred_data[sample2,])
YgivenGXQ.Pred_D0[sample1] <- stats::predict(YgivenDGXQ.Model.sample2, newdata = pred_data[sample1,])

pred_data <- data
pred_data[,D] <- 1
YgivenGXQ.Pred_D1[sample2] <- stats::predict(YgivenDGXQ.Model.sample1, newdata = pred_data[sample2,])
YgivenGXQ.Pred_D1[sample1] <- stats::predict(YgivenDGXQ.Model.sample2, newdata = pred_data[sample1,])

pred_data <- data
DgivenGXQ.Pred[sample2] <- stats::predict(DgivenGXQ.Model.sample1, newdata = pred_data[sample2,], type="prob")[,2]
DgivenGXQ.Pred[sample1] <- stats::predict(DgivenGXQ.Model.sample2, newdata = pred_data[sample1,], type="prob")[,2]

# Estimate E(Y_d | Q,g)
# IPOs for modelling E(Y_d | Q,g)
IPO_D0 <- (1-data[,D])/(1-DgivenGXQ.Pred)/mean((1-data[,D])/(1-DgivenGXQ.Pred))*(data[,Y]-YgivenGXQ.Pred_D0) + YgivenGXQ.Pred_D0
IPO_D1 <- data[,D]/DgivenGXQ.Pred/mean(data[,D]/DgivenGXQ.Pred)*(data[,Y]-YgivenGXQ.Pred_D1) + YgivenGXQ.Pred_D1

data$Q_squared <- data[,Q]^2   # add a squared term for Q

data_temp <- data[,c(G,Q,"Q_squared")]
data_temp$IPO_D0 <- IPO_D0
data_temp$IPO_D1 <- IPO_D1

Y0givenGQ.Model <- stats::lm(stats::as.formula(paste("IPO_D0", paste(paste(G,c(Q,"Q_squared"),sep="*"),collapse="+"), sep="~")), data=data_temp)
Y1givenGQ.Model <- stats::lm(stats::as.formula(paste("IPO_D1", paste(paste(G,c(Q,"Q_squared"),sep="*"),collapse="+"), sep="~")), data=data_temp)

Y0givenQ.Pred_G0 <- Y0givenQ.Pred_G1 <- Y1givenQ.Pred_G0 <- Y1givenQ.Pred_G1 <- rep(NA, nrow(data))

pred_data <- data
pred_data[,G] <- 1
Y0givenQ.Pred_G1 <- stats::predict(Y0givenGQ.Model, newdata = pred_data) 
Y1givenQ.Pred_G1 <- stats::predict(Y1givenGQ.Model, newdata = pred_data)

pred_data <- data
pred_data[,G] <- 0
Y0givenQ.Pred_G0 <- stats::predict(Y0givenGQ.Model, newdata = pred_data)
Y1givenQ.Pred_G0 <- stats::predict(Y1givenGQ.Model, newdata = pred_data)

# Estimate E(D | Q,g')
DgivenGQ.Model <- stats::glm(stats::as.formula(paste(D, paste(paste(G,c(Q,"Q_squared"),sep="*"),collapse="+"), sep="~")), data=data, family=stats::binomial(link="logit"))

DgivenQ.Pred_G0 <- DgivenQ.Pred_G1 <- rep(NA, nrow(data))

pred_data <- data
pred_data[,G] <- 0
DgivenQ.Pred_G0 <- stats::predict(DgivenGQ.Model, newdata = pred_data, type="response")

pred_data <- data
pred_data[,G] <- 1
DgivenQ.Pred_G1 <- stats::predict(DgivenGQ.Model, newdata = pred_data, type="response")

# Estimate p_g(Q)=Pr(G=g | Q)
data[,G] <- as.factor(data[,G])
levels(data[,G]) <- c("G0","G1")  # necessary for caret implementation of ranger

message <- utils::capture.output( GgivenQ.Model.sample1 <- caret::train(stats::as.formula(paste(G, paste(Q,collapse="+"), sep="~")), data=data[sample1,], method="nnet",
                                                                        preProc=c("center","scale"), trControl=caret::trainControl(method="cv"), linout=FALSE ))
message <- utils::capture.output( GgivenQ.Model.sample2 <- caret::train(stats::as.formula(paste(G, paste(Q,collapse="+"), sep="~")), data=data[sample2,], method="nnet",
                                                                        preProc=c("center","scale"), trControl=caret::trainControl(method="cv"), linout=FALSE ))
data[,G] <- as.numeric(data[,G])-1

GgivenQ.Pred <- rep(NA, nrow(data))
GgivenQ.Pred[sample2] <- stats::predict(GgivenQ.Model.sample1, newdata = data[sample2,], type="prob")[,2]
GgivenQ.Pred[sample1] <- stats::predict(GgivenQ.Model.sample2, newdata = data[sample1,], type="prob")[,2]

cond_result_nnet <- cdgd1_manual(Y=Y,D=D,G=G,
                                   YgivenGXQ.Pred_D0=YgivenGXQ.Pred_D0,
                                   YgivenGXQ.Pred_D1=YgivenGXQ.Pred_D1,
                                   DgivenGXQ.Pred=DgivenGXQ.Pred,
                                   Y0givenQ.Pred_G0=Y0givenQ.Pred_G0,
                                   Y0givenQ.Pred_G1=Y0givenQ.Pred_G1,
                                   Y1givenQ.Pred_G0=Y1givenQ.Pred_G0,
                                   Y1givenQ.Pred_G1=Y1givenQ.Pred_G1,
                                   DgivenQ.Pred_G0=DgivenQ.Pred_G0,
                                   DgivenQ.Pred_G1=DgivenQ.Pred_G1,
                                   GgivenQ.Pred=GgivenQ.Pred,
                                   data,alpha=0.05)



### gbm + parametric

set.seed(1)
# estimate the nuisance functions with cross-fitting
sample1 <- sample(nrow(data), floor(nrow(data)/2), replace=FALSE)
sample2 <- setdiff(1:nrow(data), sample1)

# outcome regression model
message <- utils::capture.output( YgivenDGXQ.Model.sample1 <- caret::train(stats::as.formula(paste(Y, paste(D,G,paste(Q,collapse="+"),paste(X,collapse="+"),sep="+"), sep="~")), data=data[sample1,], method="gbm",
                                                                           trControl=caret::trainControl(method="cv")) )
message <- utils::capture.output( YgivenDGXQ.Model.sample2 <- caret::train(stats::as.formula(paste(Y, paste(D,G,paste(Q,collapse="+"),paste(X,collapse="+"),sep="+"), sep="~")), data=data[sample2,], method="gbm",
                                                                           trControl=caret::trainControl(method="cv")) )

# propensity score model
data[,D] <- as.factor(data[,D])
levels(data[,D]) <- c("D0","D1")  # necessary for caret implementation of ranger

message <- utils::capture.output( DgivenGXQ.Model.sample1 <- caret::train(stats::as.formula(paste(D, paste(G,paste(Q,collapse="+"),paste(X,collapse="+"),sep="+"), sep="~")), data=data[sample1,], method="gbm",
                                                                          trControl=caret::trainControl(method="cv")) )
message <- utils::capture.output( DgivenGXQ.Model.sample2 <- caret::train(stats::as.formula(paste(D, paste(G,paste(Q,collapse="+"),paste(X,collapse="+"),sep="+"), sep="~")), data=data[sample2,], method="gbm",
                                                                          trControl=caret::trainControl(method="cv")) )
data[,D] <- as.numeric(data[,D])-1

# cross-fitted predictions
YgivenGXQ.Pred_D0 <- YgivenGXQ.Pred_D1 <- DgivenGXQ.Pred <- rep(NA, nrow(data))

pred_data <- data
pred_data[,D] <- 0
YgivenGXQ.Pred_D0[sample2] <- stats::predict(YgivenDGXQ.Model.sample1, newdata = pred_data[sample2,])
YgivenGXQ.Pred_D0[sample1] <- stats::predict(YgivenDGXQ.Model.sample2, newdata = pred_data[sample1,])

pred_data <- data
pred_data[,D] <- 1
YgivenGXQ.Pred_D1[sample2] <- stats::predict(YgivenDGXQ.Model.sample1, newdata = pred_data[sample2,])
YgivenGXQ.Pred_D1[sample1] <- stats::predict(YgivenDGXQ.Model.sample2, newdata = pred_data[sample1,])

pred_data <- data
DgivenGXQ.Pred[sample2] <- stats::predict(DgivenGXQ.Model.sample1, newdata = pred_data[sample2,], type="prob")[,2]
DgivenGXQ.Pred[sample1] <- stats::predict(DgivenGXQ.Model.sample2, newdata = pred_data[sample1,], type="prob")[,2]

# Estimate E(Y_d | Q,g)
# IPOs for modelling E(Y_d | Q,g)
IPO_D0 <- (1-data[,D])/(1-DgivenGXQ.Pred)/mean((1-data[,D])/(1-DgivenGXQ.Pred))*(data[,Y]-YgivenGXQ.Pred_D0) + YgivenGXQ.Pred_D0
IPO_D1 <- data[,D]/DgivenGXQ.Pred/mean(data[,D]/DgivenGXQ.Pred)*(data[,Y]-YgivenGXQ.Pred_D1) + YgivenGXQ.Pred_D1

data$Q_squared <- data[,Q]^2   # add a squared term for Q

data_temp <- data[,c(G,Q,"Q_squared")]
data_temp$IPO_D0 <- IPO_D0
data_temp$IPO_D1 <- IPO_D1

Y0givenGQ.Model <- stats::lm(stats::as.formula(paste("IPO_D0", paste(paste(G,c(Q,"Q_squared"),sep="*"),collapse="+"), sep="~")), data=data_temp)
Y1givenGQ.Model <- stats::lm(stats::as.formula(paste("IPO_D1", paste(paste(G,c(Q,"Q_squared"),sep="*"),collapse="+"), sep="~")), data=data_temp)

Y0givenQ.Pred_G0 <- Y0givenQ.Pred_G1 <- Y1givenQ.Pred_G0 <- Y1givenQ.Pred_G1 <- rep(NA, nrow(data))

pred_data <- data
pred_data[,G] <- 1
Y0givenQ.Pred_G1 <- stats::predict(Y0givenGQ.Model, newdata = pred_data) 
Y1givenQ.Pred_G1 <- stats::predict(Y1givenGQ.Model, newdata = pred_data)

pred_data <- data
pred_data[,G] <- 0
Y0givenQ.Pred_G0 <- stats::predict(Y0givenGQ.Model, newdata = pred_data)
Y1givenQ.Pred_G0 <- stats::predict(Y1givenGQ.Model, newdata = pred_data)

# Estimate E(D | Q,g')
DgivenGQ.Model <- stats::glm(stats::as.formula(paste(D, paste(paste(G,c(Q,"Q_squared"),sep="*"),collapse="+"), sep="~")), data=data, family=stats::binomial(link="logit"))

DgivenQ.Pred_G0 <- DgivenQ.Pred_G1 <- rep(NA, nrow(data))

pred_data <- data
pred_data[,G] <- 0
DgivenQ.Pred_G0 <- stats::predict(DgivenGQ.Model, newdata = pred_data, type="response")

pred_data <- data
pred_data[,G] <- 1
DgivenQ.Pred_G1 <- stats::predict(DgivenGQ.Model, newdata = pred_data, type="response")

# Estimate p_g(Q)=Pr(G=g | Q)
data[,G] <- as.factor(data[,G])
levels(data[,G]) <- c("G0","G1")  # necessary for caret implementation of ranger

message <- utils::capture.output( GgivenQ.Model.sample1 <- caret::train(stats::as.formula(paste(G, paste(Q,collapse="+"), sep="~")), data=data[sample1,], method="gbm",
                                                                        trControl=caret::trainControl(method="cv")) )
message <- utils::capture.output( GgivenQ.Model.sample2 <- caret::train(stats::as.formula(paste(G, paste(Q,collapse="+"), sep="~")), data=data[sample2,], method="gbm",
                                                                        trControl=caret::trainControl(method="cv")) )
data[,G] <- as.numeric(data[,G])-1

GgivenQ.Pred <- rep(NA, nrow(data))
GgivenQ.Pred[sample2] <- stats::predict(GgivenQ.Model.sample1, newdata = data[sample2,], type="prob")[,2]
GgivenQ.Pred[sample1] <- stats::predict(GgivenQ.Model.sample2, newdata = data[sample1,], type="prob")[,2]

cond_result_gbm <- cdgd1_manual(Y=Y,D=D,G=G,
                                 YgivenGXQ.Pred_D0=YgivenGXQ.Pred_D0,
                                 YgivenGXQ.Pred_D1=YgivenGXQ.Pred_D1,
                                 DgivenGXQ.Pred=DgivenGXQ.Pred,
                                 Y0givenQ.Pred_G0=Y0givenQ.Pred_G0,
                                 Y0givenQ.Pred_G1=Y0givenQ.Pred_G1,
                                 Y1givenQ.Pred_G0=Y1givenQ.Pred_G0,
                                 Y1givenQ.Pred_G1=Y1givenQ.Pred_G1,
                                 DgivenQ.Pred_G0=DgivenQ.Pred_G0,
                                 DgivenQ.Pred_G1=DgivenQ.Pred_G1,
                                 GgivenQ.Pred=GgivenQ.Pred,
                                 data,alpha=0.05)

##### Generate Latex tables

rd <- function(x) {format(round(x, 3), nsmall = 3)}
irl <- function(x,y,z) {
  c(interleave(rd(x), paste("(", paste(rd(y), rd(z), sep=", "), ")", sep="")))
}

# Instruction to ChatGPT: Please remove the first column and the spaces between parentheses and numbers from this latex table

### Table A5
tableA3 <- cbind(c("Total","","Baseline","","Conditional prevalence","","Conditional effect","","Conditional selection","","Q distribution","","Change in disparity",""),
                 irl(cond_result_gbm$point,cond_result_gbm$CI_lower,cond_result_gbm$CI_upper),
                 irl(cond_result_nnet$point,cond_result_nnet$CI_lower,cond_result_nnet$CI_upper),
                 irl(cond_result_ranger$point,cond_result_ranger$CI_lower,cond_result_ranger$CI_upper))
xtable(tableA3)

cbind(cond_result_gbm[,c("point","p_value")],
      cond_result_nnet[,c("point","p_value")],
      cond_result_ranger[,c("point","p_value")])
